{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created By: Rowan Converse\n",
    "#Date: 2023-03-07\n",
    "#Purpose: Consensus analysis of USFWS biologist labels of imagery from Bosque del Apache and Maxwell NWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from shapely.geometry import Polygon,Point\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import cv2 as cv\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis annotations\n",
    "path = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/data/expert/20230307_expertanalysislabels_spponly.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "  df = df[df[\"filename\"] != \"BDA_24C_20181107_1.JPG\"]\n",
    "\n",
    "#Refined annotations\n",
    "refinedpath = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/data/expert/20230307_expertconsensuslabels_spponly.csv\"\n",
    "with open(refinedpath) as f:\n",
    "  ref = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>annotation_ID</th>\n",
       "      <th>bbox_orig</th>\n",
       "      <th>filename</th>\n",
       "      <th>labeler</th>\n",
       "      <th>cat_orig</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cat_refined</th>\n",
       "      <th>bbox_refined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[4428, 2707, 125, 103]</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>steven_sesnie@fws.gov</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>0</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4445.5, 2719.5, 95.0, 80.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[4308, 2731, 105, 67]</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>steven_sesnie@fws.gov</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>1</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[4312.5, 2739.5, 98.0, 44.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[3707, 1761, 110, 101]</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>steven_sesnie@fws.gov</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3725.5, 1779.0, 73.5, 70.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[3628, 1882, 90, 38]</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>steven_sesnie@fws.gov</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>3</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3628.0, 1882.0, 92.0, 38.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[3669, 1927, 69, 82]</td>\n",
       "      <td>BDA_12C_20181127_1.JPG</td>\n",
       "      <td>steven_sesnie@fws.gov</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>4</td>\n",
       "      <td>Canadian Goose</td>\n",
       "      <td>[3679.0, 1929.0, 65.0, 82.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  annotation_ID               bbox_orig                filename  \\\n",
       "0           0              1  [4428, 2707, 125, 103]  BDA_12C_20181127_1.JPG   \n",
       "1           1              2   [4308, 2731, 105, 67]  BDA_12C_20181127_1.JPG   \n",
       "2           2              3  [3707, 1761, 110, 101]  BDA_12C_20181127_1.JPG   \n",
       "3           3              4    [3628, 1882, 90, 38]  BDA_12C_20181127_1.JPG   \n",
       "4           4              5    [3669, 1927, 69, 82]  BDA_12C_20181127_1.JPG   \n",
       "\n",
       "                 labeler        cat_orig  cluster_id     cat_refined  \\\n",
       "0  steven_sesnie@fws.gov  Canadian Goose           0  Canadian Goose   \n",
       "1  steven_sesnie@fws.gov  Canadian Goose           1  Canadian Goose   \n",
       "2  steven_sesnie@fws.gov  Canadian Goose           2  Canadian Goose   \n",
       "3  steven_sesnie@fws.gov  Canadian Goose           3  Canadian Goose   \n",
       "4  steven_sesnie@fws.gov  Canadian Goose           4  Canadian Goose   \n",
       "\n",
       "                   bbox_refined  \n",
       "0  [4445.5, 2719.5, 95.0, 80.5]  \n",
       "1  [4312.5, 2739.5, 98.0, 44.0]  \n",
       "2  [3725.5, 1779.0, 73.5, 70.5]  \n",
       "3  [3628.0, 1882.0, 92.0, 38.0]  \n",
       "4  [3679.0, 1929.0, 65.0, 82.0]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df[df[\"cluster_id\"] == -1]\n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_23201/3555870435.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  clusters = df.groupby(\"filename\")[\"bbox_orig\",\"cluster_id\",\"labeler\"].nunique()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox_orig</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>labeler</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BDA_12C_20181127_1.JPG</th>\n",
       "      <td>841</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_12C_20181127_2.JPG</th>\n",
       "      <td>3817</td>\n",
       "      <td>489</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_12C_20181127_3.JPG</th>\n",
       "      <td>4867</td>\n",
       "      <td>793</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_1.JPG</th>\n",
       "      <td>1622</td>\n",
       "      <td>164</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_2.JPG</th>\n",
       "      <td>3497</td>\n",
       "      <td>356</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_3.JPG</th>\n",
       "      <td>438</td>\n",
       "      <td>63</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_4.JPG</th>\n",
       "      <td>1145</td>\n",
       "      <td>116</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_1.JPG</th>\n",
       "      <td>780</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_2.JPG</th>\n",
       "      <td>201</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_3.JPG</th>\n",
       "      <td>895</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_4.JPG</th>\n",
       "      <td>839</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mxw_L13_20181215_1.JPG</th>\n",
       "      <td>381</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bbox_orig  cluster_id  labeler\n",
       "filename                                               \n",
       "BDA_12C_20181127_1.JPG         841          86       10\n",
       "BDA_12C_20181127_2.JPG        3817         489        8\n",
       "BDA_12C_20181127_3.JPG        4867         793        6\n",
       "BDA_18A4_20181106_1.JPG       1622         164       10\n",
       "BDA_18A4_20181106_2.JPG       3497         356       10\n",
       "BDA_18A4_20181106_3.JPG        438          63        7\n",
       "BDA_18A4_20181106_4.JPG       1145         116       10\n",
       "BDA_18A4_20181107_1.JPG        780          79       10\n",
       "BDA_18A4_20181107_2.JPG        201          27        7\n",
       "BDA_18A4_20181107_3.JPG        895          90       10\n",
       "BDA_18A4_20181107_4.JPG        839          85       10\n",
       "mxw_L13_20181215_1.JPG         381          39       10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = df.groupby(\"filename\")[\"bbox_orig\",\"cluster_id\",\"labeler\"].nunique()\n",
    "c = clusters.reset_index()\n",
    "c[\"expected\"] = c[\"bbox_orig\"]/c[\"labeler\"]\n",
    "c[\"diff\"] = c[\"cluster_id\"]/c[\"expected\"]\n",
    "clusters.to_csv()\n",
    "#pd.eval(\"c['diff'] > 1.1 or c['diff'] < 0.9\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/data/expert/\"\n",
    "#exportanalysis = datetime.now().strftime('%Y%m%d_zooniverseanalysislabels_seagull_nodrops.csv')\n",
    "clusters.to_csv(path+\"clustercheck.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9402985074626865, 1.0248886560125754)\n",
      "0.02409051426821127\n",
      "0.0005803528777068907\n"
     ]
    }
   ],
   "source": [
    "def minmax(val_list):\n",
    "    min_val = min(val_list)\n",
    "    max_val = max(val_list)\n",
    "\n",
    "    return (min_val, max_val)\n",
    "\n",
    "print(minmax(c[\"diff\"]))\n",
    "print(c[\"diff\"].std())\n",
    "print(c[\"diff\"].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/scripts/label-consensus-analysis/expertconsensus.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/scripts/label-consensus-analysis/expertconsensus.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m prediction \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mcat_orig\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/scripts/label-consensus-analysis/expertconsensus.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ground_truth \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mcat_refined\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/scripts/label-consensus-analysis/expertconsensus.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m precision \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mprecision_score(ground_truth, prediction)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/scripts/label-consensus-analysis/expertconsensus.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(precision)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/scripts/label-consensus-analysis/expertconsensus.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m recall \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mrecall_score(ground_truth, prediction)\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1776\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[1;32m   1648\u001b[0m     y_true,\n\u001b[1;32m   1649\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1655\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1656\u001b[0m ):\n\u001b[1;32m   1657\u001b[0m     \u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \n\u001b[1;32m   1659\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1776\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1777\u001b[0m         y_true,\n\u001b[1;32m   1778\u001b[0m         y_pred,\n\u001b[1;32m   1779\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1780\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1781\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1782\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1783\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1784\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1785\u001b[0m     )\n\u001b[1;32m   1786\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1562\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1563\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1565\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1364\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1364\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1365\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/sklearn/utils/multiclass.py:335\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    332\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39minput_name)\n\u001b[1;32m    333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[0;32m--> 335\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39;49munique(y)) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(y[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix  \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/numpy/lib/arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    271\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts)\n\u001b[1;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    275\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dronesforducks/lib/python3.8/site-packages/numpy/lib/arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    331\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    335\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "#ground_truth = [\"cat\", \"cat\", \"others\", \"cat\", \"others\", \"others\",\"cat\", \"cat\", \"cat\", \"others\" ]\n",
    "#prediction = [\"cat\", \"others\", \"cat\", \"cat\", \"others\", \"others\",\"cat\", \"others\", \"others\", \"cat\"]\n",
    "prediction = df[\"cat_orig\"]\n",
    "ground_truth = df[\"cat_refined\"]\n",
    "precision = sklearn.metrics.precision_score(ground_truth, prediction)\n",
    "print(precision)\n",
    "recall = sklearn.metrics.recall_score(ground_truth, prediction)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labeler                          agree\n",
       "andrew_stetter@fws.gov           Yes       949\n",
       "                                 No        196\n",
       "barry_wilson@fws.gov             Yes      1669\n",
       "                                 No        646\n",
       "bill_johnson@fws.gov             Yes      1497\n",
       "                                 No        486\n",
       "dan_collins@fws.gov              Yes      1069\n",
       "                                 No        326\n",
       "david.butler@tpwd.texas.gov      Yes      1873\n",
       "                                 No        874\n",
       "jeff_sanchez@fws.gov             Yes      1460\n",
       "                                 No        331\n",
       "jena_moon@fws.gov                No        590\n",
       "                                 Yes       486\n",
       "john_vradenburg@fws.gov          Yes      1205\n",
       "                                 No        221\n",
       "josh_vest@fws.gov                Yes       497\n",
       "                                 No         11\n",
       "jude_smith@fws.gov               No       1072\n",
       "                                 Yes       772\n",
       "kammie_kruse@fws.gov             Yes       795\n",
       "                                 No        165\n",
       "mbrasher@ducks.org               Yes       468\n",
       "                                 No         17\n",
       "ronald_deroche@fws.gov           Yes       445\n",
       "                                 No         40\n",
       "stephen.mcdowell@tpwd.texas.gov  Yes      1039\n",
       "                                 No         57\n",
       "steven_sesnie@fws.gov            Yes        63\n",
       "                                 No          5\n",
       "Name: agree, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cluster reliability: Group by filename, labeler-- count the number of original bounding boxes per labeler, get range/variance\n",
    "df['agree'] = 'No'\n",
    "df.loc[df['cat_orig'] == df[\"cat_refined\"], 'agree'] = 'Yes'\n",
    "df.groupby(\"labeler\")[\"agree\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labeler                 cat_refined       agree\n",
       "andrew_stetter@fws.gov  American Wigeon   No         3\n",
       "                                          Yes        3\n",
       "                        Canadian Goose    Yes      100\n",
       "                        Gadwall           Yes        3\n",
       "                                          No         2\n",
       "                                                  ... \n",
       "steven_sesnie@fws.gov   Canadian Goose    Yes       43\n",
       "                        Mallard           Yes        8\n",
       "                                          No         3\n",
       "                        Northern Pintail  Yes        3\n",
       "                        Sandhill Crane    Yes        9\n",
       "Name: agree, Length: 181, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"labeler\",\"cat_refined\"])[\"agree\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename\n",
       "BDA_12C_20181127_1.JPG        (68, 93)\n",
       "BDA_12C_20181127_2.JPG      (288, 570)\n",
       "BDA_12C_20181127_3.JPG     (220, 1043)\n",
       "BDA_18A4_20181106_1.JPG     (159, 165)\n",
       "BDA_18A4_20181106_2.JPG     (300, 367)\n",
       "BDA_18A4_20181106_3.JPG       (62, 66)\n",
       "BDA_18A4_20181106_4.JPG     (113, 117)\n",
       "BDA_18A4_20181107_1.JPG       (75, 83)\n",
       "BDA_18A4_20181107_2.JPG       (26, 36)\n",
       "BDA_18A4_20181107_3.JPG       (88, 91)\n",
       "BDA_18A4_20181107_4.JPG       (83, 86)\n",
       "mxw_L13_20181215_1.JPG        (38, 39)\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range = df.groupby(['filename', 'labeler']).size()\n",
    "r = range.reset_index()\n",
    "\n",
    "r.rename( columns={0 :'count'}, inplace=True )\n",
    "r.groupby(\"filename\")[\"count\"].apply(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Duck     2183\n",
       "Goose     140\n",
       "Crane      52\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set supercategories for taxa, export to separate CSV\n",
    "#spplist = ['Canadian Goose', 'Sandhill Crane', 'Mallard','Northern Pintail','American Wigeon','Other','Teal','Gadwall','Northern Shoveler']\n",
    "ref['class'] = 'Duck'\n",
    "ref.loc[ref['category'] == \"Canadian Goose\", 'class'] = 'Goose'\n",
    "ref.loc[ref['category'] == \"Sandhill Crane\", 'class'] = 'Crane'\n",
    "ref['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sa'doun's confusion matrix code\n",
    "def iou(x1, y1,w1,h1,x2, y2, w2, h2):\n",
    "    w_intersection = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_intersection = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_intersection <= 0 or h_intersection <= 0: # No overlap\n",
    "        return 0\n",
    "    I = w_intersection * h_intersection\n",
    "    U = w1 * h1 + w2 * h2 - I # Union = Total Area - I\n",
    "    return I / U\n",
    "\n",
    "def class_conf(ground,pred,iou):\n",
    "  \n",
    "  classes = ground['class'].unique()\n",
    "  cm=np.zeros((len(classes), len(classes)+2))\n",
    "\n",
    "  for i in range(len(pred)):\n",
    "    iou_list = []\n",
    "    class_list=[]\n",
    "    x=ground.loc[ground['filename'] == pred.iloc[i][0]]\n",
    "    for j in range(len(x)):\n",
    "      iou_list.append(iou(pred.iloc[i][1],pred.iloc[i][2],pred.iloc[i][3]-pred.iloc[i][1],pred.iloc[i][4]-pred.iloc[i][2],x.iloc[j][1],x.iloc[j][2],x.iloc[j][3]-x.iloc[j][1],x.iloc[j][4]-x.iloc[j][2]))\n",
    "      class_list.append(x.iloc[j][5])\n",
    "    if iou_list == []:\n",
    "      continue\n",
    "    if max(iou_list) == 0:\n",
    "      cm[int(pred.iloc[i]['class'])][-1]+=1\n",
    "    else:\n",
    "      cm[class_list[iou_list.index(max(iou_list))]][int(pred.iloc[i]['class'])]+=1\n",
    "\n",
    "  for i in range(len(cm)):\n",
    "    cm[i][-2]=len(ground.loc[ground['class'] == i])- np.sum(cm[i][:-1])\n",
    "    \n",
    "  return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for bounding boxes solution from: https://towardsdatascience.com/confusion-matrix-and-object-detection-f0cbcb634157\n",
    "\n",
    "def evaluation(ground,pred,iou_value):\n",
    "  \"\"\"\n",
    "  ground= array of ground-truth contours.\n",
    "  preds = array of predicted contours.\n",
    "  iou_value= iou treshold for TP and otherwise.\n",
    "  \"\"\"\n",
    "  truth=np.squeeze(ground)\n",
    "  preds=np.squeeze(pred)\n",
    "  #we will use this function to check iou less than threshold\n",
    "  def CheckLess(list1,val):\n",
    "    return(all(x<=val for x in list1))\n",
    "\n",
    "  # Using predicted output as the reference\n",
    "  prob1=[]\n",
    "  for i in range(len(preds)):\n",
    "      f1=preds[i]\n",
    "      # define a Shapely polygone for prediction i\n",
    "      f1=shapely.geometry.Polygon(f1)\n",
    "      # determine the radius\n",
    "      f1_radius=np.sqrt((f1.area)/np.pi)\n",
    "      #buffer the polygon fromt the centroid\n",
    "      f1_buffered=shapely.geometry.Point(f1.centroid).buffer(f1_radius*500)\n",
    "      cont=[]\n",
    "      for i in range(len(truth)):\n",
    "        ff=shapely.geometry.Polygon(np.squeeze(truth[i]))\n",
    "        if f1_buffered.contains(ff)== True:\n",
    "          iou=(ff.intersection(f1).area)/(ff.union(f1).area)  \n",
    "       \n",
    "          cont.append((iou))\n",
    "\n",
    "      prob1.append(cont)\n",
    "\n",
    "  fp=0\n",
    "\n",
    "  for t in prob1:\n",
    "    if CheckLess(t,iou_value)==True:\n",
    "      fp=fp+1\n",
    "    \n",
    "  prob2=[]\n",
    "  #loop through each groun truth instance \n",
    "  for i in range(len(truth)):\n",
    "      f1=truth[i]\n",
    "      f1=shapely.geometry.Polygon(f1)\n",
    "      #find radius\n",
    "      f1_radius=np.sqrt((f1.area)/np.pi)\n",
    "      #buffer the polygon from the centroid\n",
    "      f1_buffered=shapely.geometry.Point(f1.centroid).buffer(f1_radius*500)\n",
    "      cont=[]\n",
    "      # merge up the ground truth instance against prediction\n",
    "      # to determine the IoU\n",
    "      for i in range(len(preds)):\n",
    "        ff=shapely.geometry.Polygon(np.squeeze(preds[i]))\n",
    "        if f1_buffered.contains(ff)== True:\n",
    "          #calculate IoU\n",
    "          iou=(ff.intersection(f1).area)/(ff.union(f1).area)\n",
    "          cont.append((iou))\n",
    "      # probability of a given prediction to be contained in a\n",
    "      # ground truth instance\n",
    "      prob2.append(cont)\n",
    "  fn=0\n",
    "  tp=0\n",
    "  for t in prob2:\n",
    "    if np.sum(t)==0:\n",
    "      fn=fn+1\n",
    "    elif CheckLess(t,iou_value)==False:\n",
    "      tp=tp+1\n",
    "  \n",
    "  #lets add this section just to print the results\n",
    "  print(\"TP:\",tp,\"\\t FP:\",fp,\"\\t FN:\",fn,\"\\t GT:\",truth.shape[0])\n",
    "  precision=round(tp/(tp+fp),3) \n",
    "  recall=round(tp/(tp+fn),3)\n",
    "  f1= round(2*((precision*recall)/(precision+recall)),3)\n",
    "  print(\"Precall:\",precision,\"\\t Recall:\",recall, \"\\t F1 score:\",f1)\n",
    "  \n",
    "  return tp,fp,fn,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUTS\n",
    "\n",
    "#Line graph of average identification consensus across all images (y; % agreement) by individual (x). One for expert, one for crowdsourced.  \n",
    "#Bar graph of consensus (y; % agreement) by morphology (x; duck/goose/crane). Two bars per class, one for expert, one for crowdsourced\n",
    "#Line graph of average count consensus across all images (y; % agreement) by individual (x). One for expert, one for crowdsourced.  \n",
    "#Line graph of consensus (y; % agreement) by density (x; consensus # of individuals per image). One line for expert, one line for crowdsourced.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
