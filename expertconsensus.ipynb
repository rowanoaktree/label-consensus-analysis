{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created By: Rowan Converse\n",
    "#Date: 2023-03-07\n",
    "#Purpose: Consensus analysis of USFWS biologist labels of imagery from Bosque del Apache and Maxwell NWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from shapely.geometry import Polygon,Point\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import cv2 as cv\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis annotations\n",
    "path = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/data/expert/20230307_expertanalysislabels_spponly.csv\"\n",
    "with open(path) as f:\n",
    "  df = pd.read_csv(f)\n",
    "  df = df[df[\"filename\"] != \"BDA_24C_20181107_1.JPG\"]\n",
    "  df['bbox_orig'] = df['bbox_orig'].apply(ast.literal_eval)\n",
    "  #df['bbox_refined'] = df['bbox_refined'].apply(ast.literal_eval)\n",
    "\n",
    "#Refined annotations\n",
    "refinedpath = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/data/expert/20230307_expertconsensuslabels_spponly.csv\"\n",
    "with open(refinedpath) as f:\n",
    "  ref = pd.read_csv(f)\n",
    "  ref['bbox'] = ref['bbox'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Canadian Goose',\n",
       " 'Sandhill Crane',\n",
       " 'Mallard',\n",
       " 'Northern Pintail',\n",
       " 'American Wigeon',\n",
       " 'Other',\n",
       " 'Teal',\n",
       " 'Gadwall',\n",
       " 'Northern Shoveler']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spplist = list(ref[\"category\"].unique())\n",
    "spplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1238"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df[df[\"cluster_id\"] == -1]\n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/21/q9_tvtjj53n6mfprd_174cz00000gn/T/ipykernel_23201/3555870435.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  clusters = df.groupby(\"filename\")[\"bbox_orig\",\"cluster_id\",\"labeler\"].nunique()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox_orig</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>labeler</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BDA_12C_20181127_1.JPG</th>\n",
       "      <td>841</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_12C_20181127_2.JPG</th>\n",
       "      <td>3817</td>\n",
       "      <td>489</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_12C_20181127_3.JPG</th>\n",
       "      <td>4867</td>\n",
       "      <td>793</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_1.JPG</th>\n",
       "      <td>1622</td>\n",
       "      <td>164</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_2.JPG</th>\n",
       "      <td>3497</td>\n",
       "      <td>356</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_3.JPG</th>\n",
       "      <td>438</td>\n",
       "      <td>63</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181106_4.JPG</th>\n",
       "      <td>1145</td>\n",
       "      <td>116</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_1.JPG</th>\n",
       "      <td>780</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_2.JPG</th>\n",
       "      <td>201</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_3.JPG</th>\n",
       "      <td>895</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BDA_18A4_20181107_4.JPG</th>\n",
       "      <td>839</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mxw_L13_20181215_1.JPG</th>\n",
       "      <td>381</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         bbox_orig  cluster_id  labeler\n",
       "filename                                               \n",
       "BDA_12C_20181127_1.JPG         841          86       10\n",
       "BDA_12C_20181127_2.JPG        3817         489        8\n",
       "BDA_12C_20181127_3.JPG        4867         793        6\n",
       "BDA_18A4_20181106_1.JPG       1622         164       10\n",
       "BDA_18A4_20181106_2.JPG       3497         356       10\n",
       "BDA_18A4_20181106_3.JPG        438          63        7\n",
       "BDA_18A4_20181106_4.JPG       1145         116       10\n",
       "BDA_18A4_20181107_1.JPG        780          79       10\n",
       "BDA_18A4_20181107_2.JPG        201          27        7\n",
       "BDA_18A4_20181107_3.JPG        895          90       10\n",
       "BDA_18A4_20181107_4.JPG        839          85       10\n",
       "mxw_L13_20181215_1.JPG         381          39       10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = df.groupby(\"filename\")[\"bbox_orig\",\"cluster_id\",\"labeler\"].nunique()\n",
    "c = clusters.reset_index()\n",
    "c[\"expected\"] = c[\"bbox_orig\"]/c[\"labeler\"]\n",
    "c[\"diff\"] = c[\"cluster_id\"]/c[\"expected\"]\n",
    "clusters.to_csv()\n",
    "#pd.eval(\"c['diff'] > 1.1 or c['diff'] < 0.9\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"/Users/rowanconverse/Library/CloudStorage/OneDrive-UniversityofNewMexico/Dissertation/1_Chapter/consensus/data/expert/\"\n",
    "#exportanalysis = datetime.now().strftime('%Y%m%d_zooniverseanalysislabels_seagull_nodrops.csv')\n",
    "clusters.to_csv(path+\"clustercheck.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9402985074626865, 1.0248886560125754)\n",
      "0.02409051426821127\n",
      "0.0005803528777068907\n"
     ]
    }
   ],
   "source": [
    "def minmax(val_list):\n",
    "    min_val = min(val_list)\n",
    "    max_val = max(val_list)\n",
    "\n",
    "    return (min_val, max_val)\n",
    "\n",
    "print(minmax(c[\"diff\"]))\n",
    "print(c[\"diff\"].std())\n",
    "print(c[\"diff\"].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19324"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"cat_orig\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "#ground_truth = [\"cat\", \"cat\", \"others\", \"cat\", \"others\", \"others\",\"cat\", \"cat\", \"cat\", \"others\" ]\n",
    "#prediction = [\"cat\", \"others\", \"cat\", \"cat\", \"others\", \"others\",\"cat\", \"others\", \"others\", \"cat\"]\n",
    "pred = df[\"cat_orig\"].astype(str)\n",
    "ground = df[\"cat_refined\"].astype(str)\n",
    "\n",
    "#confusion_matrix = sklearn.metrics.multilabel_confusion_matrix(ground, pred)\n",
    "confusion_matrices = sklearn.metrics.multilabel_confusion_matrix(ground, pred)\n",
    "#for confusion_matrix in confusion_matrices:\n",
    "##    disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix, display_labels=ground)\n",
    "#    disp.plot(include_values=True, cmap=\"viridis\", ax=None, xticks_rotation=\"vertical\")\n",
    "#    plt.show()\n",
    "#accuracy = sklearn.metrics.accuracy_score(ground, pred) \n",
    "#precision = sklearn.metrics.precision_score(ground, pred)\n",
    "#recall = sklearn.metrics.recall_score(ground, pred)\n",
    "#F1_score = sklearn.metrics.f1_score(ground, pred) \n",
    "#print({\"Accuracy\":accuracy,\"Precision\":precision,\"Sensitivity_recall\": recall, \"Specificity\": precision,\"F1_score\": F1_score})\n",
    "\n",
    "#cm_display = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
    "#cm_display.plot()\n",
    "#plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labeler                          agree\n",
       "andrew_stetter@fws.gov           Yes       949\n",
       "                                 No        196\n",
       "barry_wilson@fws.gov             Yes      1669\n",
       "                                 No        646\n",
       "bill_johnson@fws.gov             Yes      1497\n",
       "                                 No        486\n",
       "dan_collins@fws.gov              Yes      1069\n",
       "                                 No        326\n",
       "david.butler@tpwd.texas.gov      Yes      1873\n",
       "                                 No        874\n",
       "jeff_sanchez@fws.gov             Yes      1460\n",
       "                                 No        331\n",
       "jena_moon@fws.gov                No        590\n",
       "                                 Yes       486\n",
       "john_vradenburg@fws.gov          Yes      1205\n",
       "                                 No        221\n",
       "josh_vest@fws.gov                Yes       497\n",
       "                                 No         11\n",
       "jude_smith@fws.gov               No       1072\n",
       "                                 Yes       772\n",
       "kammie_kruse@fws.gov             Yes       795\n",
       "                                 No        165\n",
       "mbrasher@ducks.org               Yes       468\n",
       "                                 No         17\n",
       "ronald_deroche@fws.gov           Yes       445\n",
       "                                 No         40\n",
       "stephen.mcdowell@tpwd.texas.gov  Yes      1039\n",
       "                                 No         57\n",
       "steven_sesnie@fws.gov            Yes        63\n",
       "                                 No          5\n",
       "Name: agree, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cluster reliability: Group by filename, labeler-- count the number of original bounding boxes per labeler, get range/variance\n",
    "df['agree'] = 'No'\n",
    "df.loc[df['cat_orig'] == df[\"cat_refined\"], 'agree'] = 'Yes'\n",
    "df.groupby(\"labeler\")[\"agree\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labeler                 cat_refined       agree\n",
       "andrew_stetter@fws.gov  American Wigeon   No         3\n",
       "                                          Yes        3\n",
       "                        Canadian Goose    Yes      100\n",
       "                        Gadwall           Yes        3\n",
       "                                          No         2\n",
       "                                                  ... \n",
       "steven_sesnie@fws.gov   Canadian Goose    Yes       43\n",
       "                        Mallard           Yes        8\n",
       "                                          No         3\n",
       "                        Northern Pintail  Yes        3\n",
       "                        Sandhill Crane    Yes        9\n",
       "Name: agree, Length: 181, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"labeler\",\"cat_refined\"])[\"agree\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename\n",
       "BDA_12C_20181127_1.JPG        (68, 93)\n",
       "BDA_12C_20181127_2.JPG      (288, 570)\n",
       "BDA_12C_20181127_3.JPG     (220, 1043)\n",
       "BDA_18A4_20181106_1.JPG     (159, 165)\n",
       "BDA_18A4_20181106_2.JPG     (300, 367)\n",
       "BDA_18A4_20181106_3.JPG       (62, 66)\n",
       "BDA_18A4_20181106_4.JPG     (113, 117)\n",
       "BDA_18A4_20181107_1.JPG       (75, 83)\n",
       "BDA_18A4_20181107_2.JPG       (26, 36)\n",
       "BDA_18A4_20181107_3.JPG       (88, 91)\n",
       "BDA_18A4_20181107_4.JPG       (83, 86)\n",
       "mxw_L13_20181215_1.JPG        (38, 39)\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range = df.groupby(['filename', 'labeler']).size()\n",
    "r = range.reset_index()\n",
    "\n",
    "r.rename( columns={0 :'count'}, inplace=True )\n",
    "r.groupby(\"filename\")[\"count\"].apply(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Duck     2183\n",
       "Goose     140\n",
       "Crane      52\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set supercategories for taxa, export to separate CSV\n",
    "#spplist = ['Canadian Goose', 'Sandhill Crane', 'Mallard','Northern Pintail','American Wigeon','Other','Teal','Gadwall','Northern Shoveler']\n",
    "ref['class'] = 'Duck'\n",
    "ref.loc[ref['category'] == \"Canadian Goose\", 'class'] = 'Goose'\n",
    "ref.loc[ref['category'] == \"Sandhill Crane\", 'class'] = 'Crane'\n",
    "ref['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sa'doun's confusion matrix code\n",
    "def iou(ground, pred):\n",
    "    x1 = ground[\"bbox\"][0]\n",
    "    y1 = ground[\"bbox\"][1]\n",
    "    w1 = ground[\"bbox\"][2]\n",
    "    h1 = ground[\"bbox\"][3]\n",
    "    \n",
    "    x2 = pred[\"bbox_orig\"][0]\n",
    "    y2 = pred[\"bbox_orig\"][1]\n",
    "    w2 = pred[\"bbox_orig\"][2]\n",
    "    h2 = pred[\"bbox_orig\"][3]\n",
    "\n",
    "    w_intersection = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_intersection = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_intersection <= 0 or h_intersection <= 0: # No overlap\n",
    "        return 0\n",
    "    I = w_intersection * h_intersection\n",
    "    U = w1 * h1 + w2 * h2 - I # Union = Total Area - I\n",
    "    return I / U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_cm(ground,pred,iou):\n",
    "  \n",
    "  classes = ground['category'].unique()\n",
    "  cm=np.zeros((len(classes), len(classes)+2))\n",
    "\n",
    "  for i in range(len(pred)):\n",
    "    iou_list = []\n",
    "    class_list=[]\n",
    "    x=ground.loc[ground['filename'] == pred.iloc[i][0]]\n",
    "    for j in range(len(x)):\n",
    "      iou_list.append(iou(pred.iloc[i][1],pred.iloc[i][2],pred.iloc[i][3]-pred.iloc[i][1],pred.iloc[i][4]-pred.iloc[i][2],x.iloc[j][1],x.iloc[j][2],x.iloc[j][3]-x.iloc[j][1],x.iloc[j][4]-x.iloc[j][2]))\n",
    "      class_list.append(x.iloc[j][5])\n",
    "    if iou_list == []:\n",
    "      continue\n",
    "    if max(iou_list) == 0:\n",
    "      cm[int(pred.iloc[i]['class'])][-1]+=1\n",
    "    else:\n",
    "      cm[class_list[iou_list.index(max(iou_list))]][int(pred.iloc[i]['class'])]+=1\n",
    "\n",
    "  for i in range(len(cm)):\n",
    "    cm[i][-2]=len(ground.loc[ground['class'] == i])- np.sum(cm[i][:-1])\n",
    "    \n",
    "  return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix for bounding boxes solution from: https://towardsdatascience.com/confusion-matrix-and-object-detection-f0cbcb634157\n",
    "\n",
    "def evaluation(ground,pred,iou_value):\n",
    "  \"\"\"\n",
    "  ground= array of ground-truth contours.\n",
    "  preds = array of predicted contours.\n",
    "  iou_value= iou treshold for TP and otherwise.\n",
    "  \"\"\"\n",
    "  truth=np.squeeze(ground)\n",
    "  preds=np.squeeze(pred)\n",
    "  #we will use this function to check iou less than threshold\n",
    "  def CheckLess(list1,val):\n",
    "    return(all(x<=val for x in list1))\n",
    "\n",
    "  # Using predicted output as the reference\n",
    "  prob1=[]\n",
    "  for i in range(len(preds)):\n",
    "      f1=preds[i]\n",
    "      # define a Shapely polygone for prediction i\n",
    "      f1=shapely.geometry.Polygon(f1)\n",
    "      # determine the radius\n",
    "      f1_radius=np.sqrt((f1.area)/np.pi)\n",
    "      #buffer the polygon fromt the centroid\n",
    "      f1_buffered=shapely.geometry.Point(f1.centroid).buffer(f1_radius*500)\n",
    "      cont=[]\n",
    "      for i in range(len(truth)):\n",
    "        ff=shapely.geometry.Polygon(np.squeeze(truth[i]))\n",
    "        if f1_buffered.contains(ff)== True:\n",
    "          iou=(ff.intersection(f1).area)/(ff.union(f1).area)  \n",
    "       \n",
    "          cont.append((iou))\n",
    "\n",
    "      prob1.append(cont)\n",
    "\n",
    "  fp=0\n",
    "\n",
    "  for t in prob1:\n",
    "    if CheckLess(t,iou_value)==True:\n",
    "      fp=fp+1\n",
    "    \n",
    "  prob2=[]\n",
    "  #loop through each groun truth instance \n",
    "  for i in range(len(truth)):\n",
    "      f1=truth[i]\n",
    "      f1=shapely.geometry.Polygon(f1)\n",
    "      #find radius\n",
    "      f1_radius=np.sqrt((f1.area)/np.pi)\n",
    "      #buffer the polygon from the centroid\n",
    "      f1_buffered=shapely.geometry.Point(f1.centroid).buffer(f1_radius*500)\n",
    "      cont=[]\n",
    "      # merge up the ground truth instance against prediction\n",
    "      # to determine the IoU\n",
    "      for i in range(len(preds)):\n",
    "        ff=shapely.geometry.Polygon(np.squeeze(preds[i]))\n",
    "        if f1_buffered.contains(ff)== True:\n",
    "          #calculate IoU\n",
    "          iou=(ff.intersection(f1).area)/(ff.union(f1).area)\n",
    "          cont.append((iou))\n",
    "      # probability of a given prediction to be contained in a\n",
    "      # ground truth instance\n",
    "      prob2.append(cont)\n",
    "  fn=0\n",
    "  tp=0\n",
    "  for t in prob2:\n",
    "    if np.sum(t)==0:\n",
    "      fn=fn+1\n",
    "    elif CheckLess(t,iou_value)==False:\n",
    "      tp=tp+1\n",
    "  \n",
    "  #lets add this section just to print the results\n",
    "  print(\"TP:\",tp,\"\\t FP:\",fp,\"\\t FN:\",fn,\"\\t GT:\",truth.shape[0])\n",
    "  precision=round(tp/(tp+fp),3) \n",
    "  recall=round(tp/(tp+fn),3)\n",
    "  f1= round(2*((precision*recall)/(precision+recall)),3)\n",
    "  print(\"Precall:\",precision,\"\\t Recall:\",recall, \"\\t F1 score:\",f1)\n",
    "  \n",
    "  return tp,fp,fn,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUTS\n",
    "\n",
    "#Line graph of average identification consensus across all images (y; % agreement) by individual (x). One for expert, one for crowdsourced.  \n",
    "#Bar graph of consensus (y; % agreement) by morphology (x; duck/goose/crane). Two bars per class, one for expert, one for crowdsourced\n",
    "#Line graph of average count consensus across all images (y; % agreement) by individual (x). One for expert, one for crowdsourced.  \n",
    "#Line graph of consensus (y; % agreement) by density (x; consensus # of individuals per image). One line for expert, one line for crowdsourced.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dronesforducks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
